{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenskit.batch import MultiEval\n",
    "from lenskit.crossfold import partition_users, SampleN\n",
    "from lenskit.algorithms import basic, als\n",
    "from lenskit.util import load_ml_ratings\n",
    "from lenskit import topn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the train-test pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = list(partition_users(load_ml_ratings(), 5, SampleN(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up and run the `MultiEval` experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = MultiEval('my-eval', recommend=20)\n",
    "eval.add_datasets(pairs, name='ML-Small')\n",
    "eval.add_algorithms(basic.Popular(), name='Pop')\n",
    "eval.add_algorithms([als.BiasedMF(f) for f in [20, 30, 40, 50]],\n",
    "                    attrs=['features'], name='ALS')\n",
    "eval.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the experiment is run, we can read its outputs.\n",
    "\n",
    "First the run metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AlgoClass</th>\n",
       "      <th>AlgoStr</th>\n",
       "      <th>DataSet</th>\n",
       "      <th>Partition</th>\n",
       "      <th>PredTime</th>\n",
       "      <th>RecTime</th>\n",
       "      <th>TrainTime</th>\n",
       "      <th>features</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RunId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Popular</td>\n",
       "      <td>Popular</td>\n",
       "      <td>ML-Small</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578916</td>\n",
       "      <td>0.278333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BiasedMF</td>\n",
       "      <td>als.BiasedMF(features=20, regularization=0.1)</td>\n",
       "      <td>ML-Small</td>\n",
       "      <td>1</td>\n",
       "      <td>0.377277</td>\n",
       "      <td>1.324478</td>\n",
       "      <td>5.426510</td>\n",
       "      <td>20.0</td>\n",
       "      <td>ALS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BiasedMF</td>\n",
       "      <td>als.BiasedMF(features=30, regularization=0.1)</td>\n",
       "      <td>ML-Small</td>\n",
       "      <td>1</td>\n",
       "      <td>0.326613</td>\n",
       "      <td>1.566073</td>\n",
       "      <td>1.300490</td>\n",
       "      <td>30.0</td>\n",
       "      <td>ALS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BiasedMF</td>\n",
       "      <td>als.BiasedMF(features=40, regularization=0.1)</td>\n",
       "      <td>ML-Small</td>\n",
       "      <td>1</td>\n",
       "      <td>0.408973</td>\n",
       "      <td>1.570634</td>\n",
       "      <td>1.904973</td>\n",
       "      <td>40.0</td>\n",
       "      <td>ALS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BiasedMF</td>\n",
       "      <td>als.BiasedMF(features=50, regularization=0.1)</td>\n",
       "      <td>ML-Small</td>\n",
       "      <td>1</td>\n",
       "      <td>0.357133</td>\n",
       "      <td>1.700047</td>\n",
       "      <td>2.390314</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ALS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AlgoClass                                        AlgoStr   DataSet  \\\n",
       "RunId                                                                      \n",
       "1       Popular                                        Popular  ML-Small   \n",
       "2      BiasedMF  als.BiasedMF(features=20, regularization=0.1)  ML-Small   \n",
       "3      BiasedMF  als.BiasedMF(features=30, regularization=0.1)  ML-Small   \n",
       "4      BiasedMF  als.BiasedMF(features=40, regularization=0.1)  ML-Small   \n",
       "5      BiasedMF  als.BiasedMF(features=50, regularization=0.1)  ML-Small   \n",
       "\n",
       "       Partition  PredTime   RecTime  TrainTime  features name  \n",
       "RunId                                                           \n",
       "1              1       NaN  0.578916   0.278333       NaN  Pop  \n",
       "2              1  0.377277  1.324478   5.426510      20.0  ALS  \n",
       "3              1  0.326613  1.566073   1.300490      30.0  ALS  \n",
       "4              1  0.408973  1.570634   1.904973      40.0  ALS  \n",
       "5              1  0.357133  1.700047   2.390314      50.0  ALS  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = pd.read_csv('my-eval/runs.csv')\n",
    "runs.set_index('RunId', inplace=True)\n",
    "runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\pyarrow\\pandas_compat.py:698: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels = getattr(columns, 'labels', None) or [\n",
      "D:\\Anaconda3\\lib\\site-packages\\pyarrow\\pandas_compat.py:725: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  return pd.MultiIndex(levels=new_levels, labels=labels, names=columns.names)\n",
      "D:\\Anaconda3\\lib\\site-packages\\pyarrow\\pandas_compat.py:742: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "      <th>user</th>\n",
       "      <th>rank</th>\n",
       "      <th>RunId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356</td>\n",
       "      <td>335</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>296</td>\n",
       "      <td>323</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>318</td>\n",
       "      <td>305</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>302</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260</td>\n",
       "      <td>284</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item  score  user  rank  RunId\n",
       "0   356    335     6     1      1\n",
       "1   296    323     6     2      1\n",
       "2   318    305     6     3      1\n",
       "3   593    302     6     4      1\n",
       "4   260    284     6     5      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs = pd.read_parquet('my-eval/recommendations.parquet')\n",
    "recs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the recommendation list, we need to build a combined set of truth data. Since this is a disjoint partition of users over a single data set, we can just concatenate the individual test frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = pd.concat((p.test for p in pairs), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set up an analysis and compute the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rla = topn.RecListAnalysis()\n",
    "rla.add_metric(topn.ndcg)\n",
    "ndcg = rla.compute(recs, truth)\n",
    "ndcg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to combine this with our run data, so that we know what algorithms and configurations we are evaluating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ndcg</th>\n",
       "      <th>AlgoClass</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th>RunId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Popular</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>BiasedMF</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>BiasedMF</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>BiasedMF</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>BiasedMF</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ndcg AlgoClass  features\n",
       "user RunId                          \n",
       "1    11      0.0   Popular       NaN\n",
       "     12      0.0  BiasedMF      20.0\n",
       "     13      0.0  BiasedMF      30.0\n",
       "     14      0.0  BiasedMF      40.0\n",
       "     15      0.0  BiasedMF      50.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg = ndcg.join(runs[['AlgoClass', 'features']], on='RunId')\n",
    "ndcg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Popular algorithm has NaN feature count, which `groupby` doesn't like; let's fill those in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg.loc[ndcg['AlgoClass'] == 'Popular', 'features'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we can compute the overall average performance for each algorithm configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlgoClass  features\n",
       "BiasedMF   20.0        0.015960\n",
       "           30.0        0.022558\n",
       "           40.0        0.025901\n",
       "           50.0        0.028949\n",
       "Popular    0.0         0.091814\n",
       "Name: ndcg, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg.groupby(['AlgoClass', 'features'])['ndcg'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
